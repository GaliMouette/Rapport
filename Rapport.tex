\documentclass[french,titlepage]{article}


% Le français est une langue magnifique
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}

% Pour les tactiques
\usepackage{lmodern}
\newcommand{\textttbf}[1]{\texttt{\textbf{#1}}}


% Pour les bouts de codes jolis
\usepackage{minted}
\usemintedstyle{vs}

% Pour les règles de déduction/inférence
\usepackage{mathpartir}

% Pour les sites webs
\usepackage{xcolor}
\usepackage{hyperref}
\definecolor{medium-blue}{rgb}{0,0,1}
\hypersetup{colorlinks, urlcolor={medium-blue}}

\begin{document}

\title{
    Stage :\\[1em]
    Application spontanée de transformations logiques en assistance au raisonnement automatique
}
\date{Du 5 juin au 28 juillet 2023}
\author{
    Alexis~CARRÉ \thanks{École Normale Supérieure de Lyon}
    \vspace{1em}
    \and
    Réalisé au Laboratoire Méthodes Formelles sous la direction de :\\[1em]
    Chantal~KELLER \thanks{Laboratoire Méthodes Formelles, Université Paris Saclay}
    \hspace{1em}
    Louise~DUBOIS~DE~PRISQUE\footnotemark[2]
    \vspace{2em}
}
\maketitle



\tableofcontents
\newpage



\section{Introduction}
\subsection{Assistant de preuve et preuves formelles}
Les assistants de preuve sont des logiciels permettant de construire une preuve formelle, parmi les plus connus nous pouvons citer Coq, Isabelle, Agda, Lean, ... Leur fonctionnement est basé sur l'interaction entre un humain et une machine. L'humain guide la recherche de preuve, en détaillant les étapes de la preuve et la machine sauvegarde ces étapes puis s'assure de leur validité.

Une preuve formelle est une démonstration construite à l'aide de règles de déduction. Ces règles modifient la proposition ou la décompose en sous-propositions. Ces règles forment les briques de base de transformations plus complexes, appelées tactiques dans Coq. La preuve se termine lorsque toutes les sous-propositions sont des axiomes ou des propositions déjà démontrées. Les axiomes sont des propositions qui sont considérées comme vraies sans avoir besoin d'être démontrées et les propositions supposées ou déjà démontrées sont appelées hypothèses. Une preuve formelle est donc une séquence de tactiques, chacune étant une proposition vraie, qui permettent de démontrer le but.

\subsection{Un peu d'automatisation}
La construction d'une preuve formelle est un travail fastidieux et chronophage. En effet, des propositions paraissant évidentes peuvent nécessiter de nombreuses étapes.
Pour faciliter cette tâche nous pouvons nous pencher sur la question : Pouvons-nous automatiser certaines étapes ? De nombreux travaux ont déjà étés réalisés sur ce sujet. Parmi eux, certains ont pour objectif d'intégrer des solveurs SMT dans des assistants de preuve~\cite{DBLP:conf/cpp/ArmandFGKTW11}.

Un solveur SMT (Satisfiability modulo theories) est un logiciel permettant de résoudre des problèmes de décision. Il combine un solveur de formule de la logique propositionnelle (Solveur SAT) à des théories pour permettre de résoudre des formules de la logique du 1\textsuperscript{er} ordre. Parmi les théories les plus utilisés nous trouvons la théorie de l'égalité, la théorie de l'arithmétique linéaire sur les entiers et la théorie de l'arithmétique linéaire sur les réels. Cependant, un solveur SMT reste limité, l'instanciation des quantificateurs est un point faible et la quantité de contraintes fait rapidement croître le temps de résolution.

L'assistant de preuve Coq repose sur le calcul des constructions inductives. C'est une logique plus expressive que la logique du 1\textsuperscript{er} ordre. Pour combiner un solveur SMT avec Coq, il est donc nécessaire de pouvoir détecter une formule qui n'est pas de la logique du 1\textsuperscript{er} ordre et essayer de la traiter en amont.

% TODO : Peut être plus détailler section suivante
% TODO : Exemples ?

\subsection{Contexte et objectifs de ce stage}
Les travaux de Louise et Chantal, en collaboration avec Valentin BLOT, s'intéressent déjà à ce sujet~\cite{DBLP:journals/corr/abs-2107-02353,DBLP:journals/corr/abs-2204-02643,DBLP:conf/cpp/Blot0CPKMV23}. Ils ont déjà implémenté plusieurs tactiques permettant de transformer des formules du calcul des constructions inductives en formules de la logique du 1\textsuperscript{er} ordre. Toutefois l'application de ces tactiques n'est pas toujours possible donc le choix de leur application est laissé à l'utilisateur. Afin d'automatiser ce processus, nous devons détecter les formules sur lesquelles ces tactiques peuvent être appliquées.

Également, l'ordre de ces tactiques n'est pas anodin. Certaines tactiques vont augmenter le nombre de tactiques qu'il est possible d'appliquer ce qui complexifie la recherche de preuve ainsi augmentant la charge de travail de l'utilisateur. Nous prêter un soin particulier à l'ordre dans lequel les appliquer. Nous avons déjà remarqué pendant nos expériences que certaines tactiques sont souvent appliquées dans le même ordre.

L'objectif de ce stage est de trouver un moyen de détecter les formules sur lesquelles les tactiques peuvent être appliquées ainsi que de trouver un ordre d'application de ces tactiques.

Ma contribution consiste en un langage de spécification permettant de décrire les conditions d'application d'une tactique. Les descriptions écrites dans ce langage sont ensuite assignées à une priorité et une tactique, puis interprétées. La tactique associée à la description la plus prioritaire dont les conditions sont vérifiées est appliquée.

% TODO : Rajouter petit plan ici
% TODO : Rajouter lien vers code (github)



\section{Environnement de travail}
\subsection{Un prototype}
Mes travaux sont réalisés sur la base d'un prototype produit par Louise. Ce prototype est un mini assistant de preuve reposant sur la déduction naturelle intuitionniste propositionnelle. Cette logique est moins expressive que le calcul des constructions inductives. Cependant, elle suffit pour les expériences réalisées. Ce mini assistant de preuve est programmé en OCaml. L'utilisation de ce langage est un atout. C'est le langage utilisé pour implémenter Coq. L'utilisation de ce prototype offre plus de liberté que d'utiliser Coq. La quantité de code à comprendre est moindre, de même que sa complexité. Le comportement de l'assistant de preuve est plus facile à prédire et à modifier. Cela permet de se concentrer pleinement sur les problématiques de détection et d'ordre. Le code du prototype initial est disponible sur GitHub\footnote{\url{https://github.com/louiseddp/MinITP}}.

\subsection{Fonctionnement du prototype} \label{FonctionnementPrototype}
Le prototype se décompose en deux parties : un module interagissant avec l'utilisateur et un noyau. Le module d'interaction avec l'utilisateur permet de lire les tactiques entrées par l'utilisateur, de les appliquer à la formule courante et d'afficher le résultat. L'application d'une tactique à la formule courante produit un arbre de preuve contenant les tactiques appliquées, ainsi que les sous-buts générés restant à prouver et modélisés par des trous. Quand l'arbre de preuve ne contient plus de trou, la preuve est terminée. Une fois terminée, le noyau s'assure de la validité de l'arbre de preuve nouvellement construit.

La vérification de l'arbre de preuve est une étape cruciale, car une erreur logique dans celle-ci permettrait de prouver n'importe quelle formule. Ajouter du code au noyau est une tâche délicate et risque d'introduire des comportements inattendus. S'assurer que les changements apportés n'ont pas d'impacts indésirés est laborieux. C'est pourquoi le noyau est séparé du module d'interaction avec l'utilisateur. Cela permet de minimiser la quantité de code le composant et de réduire la confiance que nous devons lui accorder.

% TODO : Exemple preuve avant modifs ?



\section{Réalisation}
\subsection{De nouvelles tactiques}
L'automatisation de la construction de preuve se fait par l'utilisation de tactiques. C'est le seul médium permettant d'interagir avec l'assistant de preuve. Cette automatisation peut avoir un comportement très simple, comme une tactique combinant une application successive de tactiques au style d'un raccourci, ou bien légèrement plus complexe, comme une tactique cherchant à appliquer une autre tant que possible, ou encore très complexe, comme une tactique utilisant un logiciel externe de la même façon qu'une tactique de résolution faisant appel à un solveur SMT.

Dans cette sous-section nous présentons un exemple de tactique avec un comportement simple dont nous détaillons les spécifications techniques et l'implémentation. Nous présenterons également un exemple de tactique avec un comportement plus complexe dans la section \ref{CompositionTactiques}.

\subsubsection{Spécifications techniques} \label{SpecsTactiques}
Les nouvelles tactiques implémentées sont les suivantes : $\land_{E_L}$ et $\land_{E_R}$. Elles sont définies comme suit :
\begin{mathpar}
    \inferrule* [Right=($\land_{E_L}$)] {
        \Gamma \vdash A \land B
    }{
        \Gamma \vdash A
    }
    \and
    \inferrule* [Right=($\land_{E_R}$)] {
        \Gamma \vdash A \land B
    }{
        \Gamma \vdash B
    }
\end{mathpar}
Toutes les deux permettent d'éliminer le connecteur $\land$. Également, elles sont dérivables de la règle $\land_E$. Cela signifie que nous pouvons les obtenir en combinant d'autres règles. Cette combinaison peut s'exprimer sous la forme d'un arbre de preuve. Voici les arbres de preuve correspondant à ces dérivations, à gauche la règle $\land_{E_L}$ et à droite la règle $\land_{E_R}$ :
\begin{mathpar}
    \inferrule* [Right=($\land_E$)] {
        \Gamma \vdash A \land B
        \\
        \inferrule* [Right=($Axiom$)] {
        }{
            \Gamma, A, B \vdash A
        }
    }{
        \Gamma \vdash A
    }
    \and
    \inferrule* [Right=($\land_E$)] {
        \Gamma \vdash A \land B
        \\
        \inferrule* [Right=($Axiom$)] {
        }{
            \Gamma, A, B \vdash B
        }
    }{
        \Gamma \vdash B
    }
\end{mathpar}
Et les règles utilisées pour les dériver sont les suivantes :
\begin{mathpar}
    \inferrule* [Right=($\land_E$)] {
        \Gamma \vdash A \land B
        \\
        \Gamma, A, B \vdash C
    }{
        \Gamma \vdash C
    }
    \and
    \inferrule* [Right=($Axiom$)] { } {
        \Gamma, A \vdash A
    }
\end{mathpar}
Ces arbres de preuves affiche clairement pourquoi ces tactiques simplifie la construction de preuve. Au lieu d'appliquer la règle $\land E$ puis la règle $Axiom$, nous pouvons directement appliquer la règle $\land E_L$ ou $\land E_R$. Cela permet de générer moins de sous-buts. La recherche est plus courte. L'ajout de ces tactiques ne change pas la logique sous-jacente puisqu'il était déjà possible d'appliquer manuellement les deux tactiques. C'est un premier pas vers l'automatisation de la construction de preuve.

\subsubsection{Implémentation}
Nous avons choisi pour implémenter chaque nouvelle tactique de créer une fonction dédiée. Celle-ci s'occupe de la création du morceau de l'arbre de preuve. Sa conception peut se faire de deux façons :
\begin{enumerate}
    \item Introduire un nouveau type de nœud dans l'arbre de preuve. Cependant, pour chaque nouveau type de nœud cette méthode implique de rajouter du code au noyau pour le vérifier. Cela va à l'encontre de la séparation entre le noyau et les tactiques mentionné dans la section \ref{FonctionnementPrototype}. Cette méthode n'est donc pas recommandée et ne sera pas utilisée.
    \item Utiliser les arbres de preuves des dérivations décrites dans la section \ref{SpecsTactiques}. Les types des nœuds nécessaires pour créer un tel arbre sont déjà présents dans le noyau et leur vérification est déjà implémentée. Cette méthode ne nécessite pas de rajouter du code au noyau. C'est donc celle que nous avons choisie. Cependant, un arbre produit par cette méthode est plus grand qu'un arbre produit par la méthode précédente. Il contient plus de nœuds et donc le temps nécessaire pour le vérifier est plus long.
\end{enumerate}

Pour implémenter la méthode que nous avons retenue, nous avons besoin de créer un morceau d'arbre de preuve. La conception de ce morceau peut se faire, soit en composant les types de nœuds de l'arbre, soit en composant les fonctions existantes. Nous abordons ces points prochainement, dans la section \ref{CompositionTactiques}, où nous présentons également un exemple de tactique avec un comportement plus complexe.

\subsection{Composition de tactiques} \label{CompositionTactiques}
Dans la méthode retenue, la fonction crée un morceau d'arbre de preuve.
Nous commençons par présenter deux façons de concevoir ce morceau. Ensuite présentons une tactique ajoutée au prototype, illustrant la composition de tactiques.

\subsubsection{Première méthode}
Dans la fonction, construire le morceau d'un trait en utilisant les types de nœuds. Cette méthode est simple à mettre en œuvre, mais elle est peu flexible. Par exemple, supposons un raccourci appliquant deux fois la tactique $\to_I$. Voici l'arbre correspondant à ce raccourci, ainsi que la définition de la règle $\to_I$ :
\begin{mathpar}
    \inferrule* [Right=($\to_I$)] {
        \inferrule* [Right=($\to_I$)] {
            \Gamma, A, B \vdash C
        }{
            \Gamma, A \vdash B \to C
        }
    }{
        \Gamma \vdash A \to B \to C
    }
    \and
    \inferrule* [Right=($\to_I$)] {
        \Gamma, A \vdash B
    }{
        \Gamma \vdash A \to B
    }
\end{mathpar}

L'utilisation de ce raccourci sur la formule $\Gamma \vdash A \to B \to C \to D$ produit le résultat $\Gamma, A, B \vdash C \to D$. Cependant, pour l'utilisateur, il est naturel de continuer d'appliquer la règle $\to_I$ pour obtenir $\Gamma, A, B, C \vdash D$. Un nouveau raccourci est nécessaire pour obtenir ce comportement, ce qui implique une nouvelle fonction, avec un morceau d'arbre de preuve différent, etc. Il faut créer une infinité de raccourcis pour obtenir tous les comportements possibles.

Le problème est que cette méthode requiert de connaitre la taille et la forme du morceau d'arbre de preuve à l'avance. Le comportement est donc fixé lors de la conception de la tactique. Cette rigidité ne permet pas de créer des tactiques génériques. C'est pourquoi nous ne l'avons pas retenue.

\subsubsection{Seconde méthode}
Faire successivement appel à chacune des fonctions, déjà existantes, qui construisent les nœuds composant l'arbre. Cette méthode est plus complexe à mettre en œuvre, mais elle est plus flexible. Elle permet de construire des morceaux d'arbre de preuve de taille et de forme variable en utilisant les fonctionnalités du langage de programmation telles que les boucles, les expressions conditionnelles, etc.

Reprenons l'exemple précédent. Notre fonction pourrait, par le biais d'une boucle, tester et tant que possible appliquer la tactique $\to E$. Le test prendre place a posteriori, par exemple l'application de la tactique déclenche une erreur si elle n'est pas applicable. Ou a priori, en analysant la formule. Une autre solution, similaire au test a priori, serait d'explorer la formule intelligemment pour compter le nombre de $\to$ et appliquer la tactique $\to E$ ce nombre de fois.

Cette méthode permet de créer des tactiques génériques avec un comportement complexe. C'est pourquoi nous avons retenu cette méthode. Cependant, elle ajoute beaucoup de complexité. Comme élaboré dans l'exemple, elle requiert les deux fonctionnalités suivantes :
\begin{enumerate}
    \item Savoir si une tactique est applicable ou non. Soit en testant en amont de l'application, soit en évaluant le résultat qu'elle produit.
    \item Explorer la formule.
\end{enumerate}
Ces fonctionnalités sont misent à l'œuvre dans la tactique $Auto$ présentée dans le paragraphe suivant. Il n'est ni nécessaire de comprendre leur fonctionnement interne, ni leur implémentation. Il suffit de comprendre leur rôle. Les détails concernant leur fonctionnement et leur mise en œuvre seront abordés à la section \ref{DetectionDeclenchement}.

\subsubsection{Extension du prototype}
L'exemple utilisé pour illustrer la seconde méthode a servi d'inspiration pour une nouvelle tactique. Cette tactique, nommée $Auto$, se compose de deux étapes : réduire une formule en une formule atomique et si la formule à prouver se trouve dans les hypothèses alors appliquer la tactique de l'axiome. La première étape signifie transformer formule constituée d'une chaine d'implications en une formule dépourvue d'implication. Ceci correspond à transformer une formule de la forme $\Gamma \vdash A \to B \to \dots \to C $ vers une formule $\Gamma, A, B, \dots \vdash C$. La seconde étape consiste à vérifier si la formule à prouver se trouve dans les hypothèses. Si c'est le cas, la tactique de l'axiome est appliquée. Sinon rien ne se passe et la main est rendue à l'utilisateur.

% TODO (À vérifier) : Peut être mentionner quelque part que tactique signifie la fonction qui construit noeud. Et que règle signifie la règle de déduction logique. Pour éviter confusion, car les règles de bases ont toutes une tactique du même nom.
% ! POUR ÇA : Mentioner dans partie 2. Une fois noyau décrit, faire tactique.

Pour créer ce comportement complexe, cette tactique combine astucieusement les autres tactiques avec les fonctionnalités du langage de programmation. Cette intrication entre le langage et la logique illustre clairement la polyvalence de la seconde méthode. En outre, ceci représente également une avancée significative vers l'automatisation.

\subsection{Détection et déclenchement automatique} \label{DetectionDeclenchement}
\subsubsection{Détection}
Nous mentionnons dans le paragraphe précédent que nous avons besoin de savoir si une tactique est applicable et nous nécessitons également d'explorer la formule. Ces exigences servent toutes les deux à récolter de l'information. Une fois cette information obtenue nous pouvons prendre des décisions en conséquence. La prise de décision sera abordée dans la section suivante.

Jusqu'à maintenant nous nous sommes concentrés sur la formule, mais cela est restrictif. Par exemple pour la tactique de l'axiome, nous devons regarder si la formule à prouver se trouve dans les hypothèses. Nous devons donc être en mesure de regarder les hypothèses pour obtenir l'ensemble des informations nécessaires. Mais plus encore, dans ce cas précis, nous devons avoir la capacité de regarder les deux simultanément.

Dans le cadre d'une tactique, la détection peut survenir à deux moments différents. Soit avant son application, soit après. Dans le premier cas, nous parlons de détection en amont. Dans le second cas, nous parlons de détection en aval. Les deux prochains paragraphes abordent ces deux cas.

\paragraph{La détection en amont :}
Du point de vue d'une tactique, détecter en amont signifie que nous regardons la formule avant de prendre une décision. Par exemple, si la formule est une conjonction, une disjonction, une implication, etc.

Ce type de détection est le plus souvent utilisé au sein même d'une tactique. Par exemple, la tactique $\to I$ ne peut être appliquée que si la formule est une implication. Et si cette même tactique ne vérifiais pas ce prérequis, alors elle pourrait être appliquée à n'importe quelle formule. Une incohérence de la sorte produira une erreur quand le noyau vérifiera l'arbre de preuve. Mais il est préférable de détecter en amont pour éviter de perdre du temps à construire une preuve qui sera rejetée par le noyau.

La détection en amont peut également de produire de l'information pour la détection en aval. C'est notamment le cas pour notre tactique auto. Nous détaillons ce point dans le paragraphe suivant.

\paragraph{La détection en aval}
Comme nous l'avons mentionné dans le paragraphe précédent, le noyau est une sorte de détection en aval. Il vérifie une fois la preuve construite si elle est correcte, c'est-à-dire que les règles logiques sont correctement utilisées. Mais ici, du point de vue d'une tactique, nous ne pouvons pas utiliser le noyau. Car l'arbre de preuve contient encore des trous. Nous devons donc nous débrouiller par nous-même.

Le principal aspect de la détection en aval consiste à regarder si une tactique a réussi à s'appliquer. Nous avons ici une communication entre la détection en amont et en aval. La détection en amont nous permettant de ne pas perdre de temps à appliquer une tactique qui ne peut pas s'appliquer ainsi que transmettre cette information. Et la détection en aval analysant cette information pour prendre une décision. C'est un point important, car cela facilite grandement la composition de tactique.

Par exemple, notre tactique $Auto$. Au lieu de regarder en boucle si la formule est une implication, nous pouvons maintenant utiliser le résultat produit par la tactique $\to I$. C'est-à-dire que si la tactique $\to I$ a réussi à s'appliquer, alors nous savons que la formule était une implication et nous récupérons le résultat après l'application de $\to I$. Et si la tactique $\to I$ n'a pas réussi à s'appliquer, alors nous savons que la formule n'est pas une implication.

\subsubsection{Déclenchement} \label{Declenchement}
Dans les paragraphes précédents, nous avons mentionné que la détection permet de récolter de l'information pour par la suite prendre des décisions. Les exemples que nous avons présentés implémentent des procédures qui utilisent ces détections pour prendre des décisions et ainsi adapter leurs comportements. Mais ces procédures ne sont pas automatiques. Nous avons toujours besoin de l'utilisateur pour déclencher la tactique.

Cependant, nous pouvons aller plus loin. Nous pouvons nous placer dans le cadre de l'interaction avec l'utilisateur. Par exemple, après que l'utilisateur a appliqué une tactique, nous pouvons détecter si parmi une liste une autre tactique peut s'appliquer et le cas échéant l'appliquer automatiquement. Ici nous obtenons un comportement complètement automatique dans lequel l'assistant de preuve viens en aide à l'utilisateur.

Il est important prendre en compte l'ordre des tactiques dans notre détection. Les tactiques produisant plusieurs sous-formules doivent être soigneusement placées. Par exemple, la tactique implémentant l'élimination la disjonction produit trois sous-formules. Si nous la plaçons avant la tactique de l'axiome, nous pouvons nous retrouver dans une situation où au lieu de terminer la preuve de la formule, nous nous retrouvons avec trois sous-formules à prouver. En plus de cela, l'élimination de la disjonction est une des tactiques qui peut s'appliquer à n'importe quelle formule. Ainsi en la plaçant en premier, la preuve risque de ne pas se terminer. L'intuition est que nous devons placer les tactiques les plus spécifiques en premier et les plus générales en dernier.

\subsubsection{Détails d'implémentation}
Dans notre prototype, nous implémentons les deux types de détections mentionnés précédemment ainsi que le déclenchement automatique.

Les tactiques de base, c'est-à-dire celles qui implémentent les règles d'inférences logiques, utilisent la détection en amont. Leur simplicité permet de directement vérifier la forme de la formule au sein de la tactique. Par exemple, la tactique $\to I$ vérifie si la formule est une implication, la tactique $\land E$ vérifie si la formule est une conjonction, etc. L'utilisateur est plus restreint et ne peux plus appliquer n'importe quelle tactique à n'importe quelle formule. Mais comme nous l'avons vue précédemment, cela permet d'éviter de perdre du temps à construire une preuve qui sera rejetée par le noyau.

Maintenant que les tactiques de bases implémentent la détection en amont, les tactiques les utilisant comment composantes peuvent utiliser la détection en aval. Cela nous permet de simplifier leur implémentation. Pour cela, nous avons conçus quelques fonctions auxiliaires, en voici quelques-unes :
\begin{itemize}
    \item \mintinline{ocaml}|fold_apply_once| : reçoit une liste de tactique puis les applique une par une sans se soucier d'un éventuel échec.
    \item \mintinline{ocaml}|fold_apply| : fonctionne comme \mintinline{ocaml}|fold_apply_once|, mais pour chaque tactique l'applique tant que possible.
    \item \mintinline{ocaml}|try_apply| : permet de ne pas appliquer une tactique si le sous-arbre de preuve ne présente plus de trou. Rajoutée à cause d'un bug, elle est utilisée dans les deux fonctions ci-dessus pour leur permettre de s'arrêter.
\end{itemize}
Avec ces fonctions, notre tactique $Auto$ se résume à une liste contenant la tactique $\to I$ et la tactique $Axiom$ que nous appliquons avec \mintinline{ocaml}|fold_apply|.
Nous avons également implémenté une tactique combinant les deux types de détection. Notre tactique $Commute$ commence par détection en amont si la formule est une conjonction ou une disjonction. Si c'est le cas, alors nous construisons les arbres respectifs avec l'aide des fonctions mention ci-dessus. Dans le cadre des tactiques de base et des tactiques les combinant, la principale utilisation de la détection est de simplifier l'implémentation notamment en évitant de répéter plusieurs fois la même détection. Par exemple, la tactique $\to I$ doit indépendamment vérifier que la formule est une implication et si la détection en aval n'était pas utilisée, alors la tactique $Auto$ devrait également le vérifier avant d'appliquer $\to I$.

Le déclenchement automatique de tactiques comme $Axiom$ ou $Auto$ reste simple. En effet, l'assistant peut juste bêtement les appeler après une interaction avec l'utilisateur. Leurs impacts sont minimes et n'augmente pas le nombre de sous-formules à prouver. Jusqu'à maintenant les formes que nous avions besoin de détecter étaient simples. La plupart du temps, il s'agissait de regarder le connecteur de la formule. C'est un problème. Par exemple, nous pouvons essayer d'appliquer la tactique $\lor E$, mais cela requiert d'être vigilant. Il n'y a aucun intérêt à l'utiliser si dans nos hypothèses nous n'avons pas une formule avec une conjonction. Nous nécessitons d'exprimer plus que la forme d'une formule. Nous abordons ce problème et notre solution dans la section suivante.

\subsection{Un langage pour détecter}
Dans la section précédente, nous introduisons brièvement le problème suivant. Le système de détection actuel est suffisant pour les tactiques, mais trop peu expressif pour le déclenchement automatique. Nous avons besoin d'exprimer plus que la forme d'une formule. Nous avons besoin d'exprimer sa position. Par exemple, nous voulons pouvoir exprimer que la formule est une hypothèse ou qu'elle est dans la conclusion. Le tout en conservant les fonctionnalités du système actuel.

\subsubsection{Syntaxe}
Notre solution consiste à créer un langage de détection et déclenchement. Nous utilisons les types d'OCaml pour définir la syntaxe suivante :
\begin{minted}{ocaml}
type trigger_var = TGoal | TSomeHyp

type trigger_form =
    | TVar of string
    | TArr of trigger_form * trigger_form
    | TAnd of trigger_form * trigger_form
    | TOr of trigger_form * trigger_form
    | TTop
    | TBottom
    | TDiscard
    | TMetaVar

type trigger =
    | TEq of trigger_var * trigger_var
    | TIs of trigger_var * trigger_form
    | TContains of trigger_var * trigger_form
\end{minted}

Le type \mintinline{ocaml}|trigger_var| permet de définir la position de la formule. \mintinline{ocaml}|TGoal| représente la conclusion et \mintinline{ocaml}|TSomeHyp| représente une hypothèse quelconque.

Le type \mintinline{ocaml}|trigger_form| permet de définir la forme de la formule. Cette partie du système réimplémente le système précédent. \mintinline{ocaml}|TVar| représente une variable du point de vue de la formule. \mintinline{ocaml}|TArr|, \mintinline{ocaml}|TAnd| et \mintinline{ocaml}|TOr| représentent respectivement une implication, une conjonction et une disjonction. \mintinline{ocaml}|TTop| et \mintinline{ocaml}|TBottom| représentent la formule vraie et la formule fausse. \mintinline{ocaml}|TDiscard| et \mintinline{ocaml}|TMetaVar| sont deux nouveautés. \mintinline{ocaml}|TDiscard| permet de définir une formule qui sera ignorée et \mintinline{ocaml}|TMetaVar| permet de définir une variable qui sera remplacée par une formule quelconque. Leur utilité sera expliquée dans la section suivante.

Le type \mintinline{ocaml}|trigger| permet de définir une détection. \mintinline{ocaml}|TEq| établit une égalité entre deux variables. \mintinline{ocaml}|TIs| vérifie si la variable est une formule de la forme donnée. \mintinline{ocaml}|TContains| fonctionne presque comme \mintinline{ocaml}|TIs|, mais explore la formule en profondeur et vérifie si une sous formule a la forme donnée.

\paragraph{Quelques exemples :}
\begin{itemize}
    \item \mintinline{ocaml}|TIs (TGoal, TVar "A")| : vérifie si la conclusion est une variable $A$.
    \item \mintinline{ocaml}|TContains (TSomeHyp, TVar "A")| : vérifie si une hypothèse quelconque contient une variable $A$.
    \item \mintinline{ocaml}|TEq (TGoal, TSomeHyp)| : vérifie si la conclusion est une hypothèse quelconque. C'est le déclencheur pour la tactique $Axiom$.
    \item \mintinline{ocaml}|TIs (TGoal, TAnd(TDiscard, TDiscard))| : vérifie si la conclusion est une conjonction. C'est le déclencheur pour la tactique $\land I$.
\end{itemize}

\subsubsection{Interprétation}

\paragraph{Variables}
Une variable de déclenchement prend une valeur lors de l'interprétation. Il en existe deux : \mintinline{ocaml}|TGoal| et \mintinline{ocaml}|TSomeHyp|. Lors de l'interprétation \mintinline{ocaml}|TGoal| prends la valeur du but courant et \mintinline{ocaml}|TSomeHyp| donne accès à la liste des hypothèses. Utiliser une liste contenant toutes les hypothèses permet d'émuler le comportement : est-ce qu'il existe une hypothèse qui vérifie la condition ? Pour cela, il suffit de prendre un à un les éléments de la liste et le premier qui vérifie la condition est retourné. Si aucun élément ne vérifie la condition, alors la détection échoue.

\paragraph{Formes}
L'interprétation de la forme est similaire à celle utilisée dans les tactiques. Dans les tactiques, nous utilisons des disjonctions de cas, ce qui nécessite dupliquer une partie du code pour chaque cas. Ici, grace au type \mintinline{ocaml}|trigger_form|, nous implémentons un système générique. La fonction d'interprétation prend en paramètre une formule et une forme et retourne, soit un échec, soit une liste de formules. C'est dans l'élaboration de cette liste qu'interviennent les constructeurs \mintinline{ocaml}|TMetaVar| et \mintinline{ocaml}|TDiscard|.

Par exemple, avec la forme \mintinline{ocaml}|TAnd(TMetaVar, TDiscard)| interprété sur la formule $A \land B$, la fonction retournera la liste $[A]$. En effet, \mintinline{ocaml}|TMetaVar| est remplacé par $A$ et \mintinline{ocaml}|TDiscard| est ignoré.

Il est important de noter la différence entre \mintinline{ocaml}|TMetaVar| et \mintinline{ocaml}|TVar|. \mintinline{ocaml}|TMetaVar| est utilisé lors de l'interprétation pour récupérer des morceaux de formules. \mintinline{ocaml}|TVar| quant à elle est utilisée lors de la vérification de la forme. Par exemple, avec la forme \mintinline{ocaml}|TAnd(TVar "A", TDiscard)| interprété sur la formule $B \land C$, la fonction retournera un échec. En effet, la variable utilisé dans la formule est $B$ et non $A$.

\paragraph{Déclencheurs}
L'interprétation du déclencheur est constituée de deux composants. Le premier est l'interprétation des constructeurs \mintinline{ocaml}|TEq|, \mintinline{ocaml}|TIs| et \mintinline{ocaml}|TContains|. Il utilise la fonction pour interpréter la forme pour obtenir une liste de formules. Ensuite, il vérifie si la liste est vide ou non. Si elle est vide, alors la détection échoue. Sinon, il retourne la liste des formules obtenues.

Le deuxième composant utilise le premier. Dans son code, nous utilisons une liste de couples associant déclencheurs et tactiques. Pour chaque couple, nous interprétons le déclencheur et s'il réussit, nous appliquons la tactique. Ici nous utilisons implicitement l'ordre que nous mentionnons à la section \ref{Declenchement}. Par exemple, pour l'élimination de la disjonction ($\lor E$), nous pouvons utiliser le déclencheur \mintinline{ocaml}|TIs (TSomeHyp, (TOr, TMetaVar, TMetaVar))|. Cependant, un problème auquel nous faisons face est que le déclencheur peut s'appliquer plusieurs fois. En effet, à moins de supprimer l'hypothèse, la condition restera vérifiée. Pour éviter cela, nous utilisons une liste de déclencheurs ainsi que la formule associée à leur déclenchement. Ainsi, si la formule est déjà présente dans la liste et le déclencheur déjà appliqué, alors la détection échoue.



\section{Conclusion et perspectives}
\subsection{Notre contribution et nos résultats}
Dans cette étude, nous présentons des contributions substantielles dans le domaine du déclenchement et de l'application de tactiques. Nos principales contributions sont les suivantes :

Nous introduisons un nouveau langage spécialement conçu pour le déclenchement automatisé. Ce langage permet la spécification formelle des conditions qui doivent être remplies pour déclencher une action ou une série d'actions. Il est accompagné par un interpréteur permettant de le mettre en application au sein de notre prototype.

Nous abordons le défi de la conception de tactiques en proposant une approche novatrice qui intègre la détection en amont. Notre méthode permet de déterminer si une tactique spécifique est applicable dans un contexte donné. Cela garantit une utilisation plus efficace des tactiques en évitant leur application inutile lorsque les conditions requises ne sont pas réunies.

ous étendons nos contributions en proposant une méthode de composition de tactiques basée sur les résultats obtenus à partir de la détection en amont. En combinant les résultats de plusieurs tactiques, nous facilitons la création d'ensembles de tactiques optimisées pour des scénarios spécifiques. Cette approche de détection en aval garantit que les tactiques sélectionnées sont cohérentes et adaptées à l'objectif final.

\subsection{Perspectives}
Les contributions de ce stage constituent une fondation solide pour orienter nos futurs travaux de recherche. Dans ce contexte, Louise prévoit d'intégrer ces résultats dans le cadre de sa thèse en les développant davantage. En particulier, elle prévoit d'intégrer un langage pour détecter et déclencher des tactiques dans Sniper, un plugin pour l'assistant de preuve Coq.

Une tâche à venir consiste à se familiariser avec LTac2, à comprendre son fonctionnement et à explorer ses capacités. Cette phase revêt une importance cruciale pour l'évolution de nos recherches, notamment pour l'implémentation future dans Coq. En effet, LTac2 est un langage de programmation dédié à la construction de tactiques dans Coq.

Il convient de noter que LTac2 est encore en phase de développement, présentant des similitudes frappantes avec notre propre langage. Bien que les mécanismes de détection semblent étroitement liés, des différences demeurent, notamment en ce qui concerne l'aspect de l'interprétation.

L'intégration de nos travaux dans l'écosystème de Coq demeure un objectif clé pour la prochaine étape de notre recherche. Cette entreprise impliquera un travail méticuleux de traduction de concepts et de réglages fins afin d'assurer la synergie entre nos résultats et l'environnement Coq.

Une avenue prometteuse pour l'approfondissement de nos travaux consiste à explorer plus en profondeur l'ordre et son incidence sur les résultats obtenus. Jusqu'à présent, nos conclusions reposent sur des expériences empiriques et notre intuition, et il reste à établir des résultats formels qui confirment ces observations préliminaires.



\newpage
\appendix
\section{Institution d'accueil}
Le Laboratoire Méthodes Formelles (LMF) a été créé le 1er janvier 2021 suite à une décision politique des institutions qui le soutiennent, à savoir l'Université Paris-Saclay, le CNRS, l'ENS Paris-Saclay, Inria et CentraleSupélec. L'objectif principal du LMF est de se concentrer sur les méthodes formelles. Il regroupe le Laboratoire Spécification et Vérification (LSV, ENS Paris-Saclay, CNRS, Inria) et l'équipe Vals du Laboratoire de Recherche en Informatique (LRI, Université Paris-Saclay, CNRS, Inria, CentraleSupélec), ce qui représente environ une centaine de personnes.
Le LMF aspire à utiliser les méthodes formelles comme outil d'analyse, de modélisation et de raisonnement pour les programmes informatiques dans le but de s'assurer du fonctionnement correct des logiciels et du matériel.
La structure du LMF est basée sur plusieurs pôles : il comprend deux pôles centraux, "Preuves" et "Modèles", qui représentent son cœur d'activité. Le troisième pôle, "Interactions", constitue une ouverture vers d'autres domaines tels que l'intelligence artificielle et la biologie.

\bibliography{bibliography}
\bibliographystyle{unsrt}

\end{document}
